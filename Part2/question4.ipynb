{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import functions as func\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#load preprocessed data\n",
    "#df = func.getUseableHP2Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460\n",
      "1370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Id  MSSubClass MSZoning  LotArea Street          Alley LotShape  \\\n",
       "0        1          60       RL     8450   Pave  NotApplicable      Reg   \n",
       "1        2          20       RL     9600   Pave  NotApplicable      Reg   \n",
       "2        3          60       RL    11250   Pave  NotApplicable      IR1   \n",
       "3        4          70       RL     9550   Pave  NotApplicable      IR1   \n",
       "4        5          60       RL    14260   Pave  NotApplicable      IR1   \n",
       "...    ...         ...      ...      ...    ...            ...      ...   \n",
       "1455  1456          60       RL     7917   Pave  NotApplicable      Reg   \n",
       "1456  1457          20       RL    13175   Pave  NotApplicable      Reg   \n",
       "1457  1458          70       RL     9042   Pave  NotApplicable      Reg   \n",
       "1458  1459          20       RL     9717   Pave  NotApplicable      Reg   \n",
       "1459  1460          20       RL     9937   Pave  NotApplicable      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... PoolArea         PoolQC  \\\n",
       "0            Lvl    AllPub    Inside  ...        0  NotApplicable   \n",
       "1            Lvl    AllPub       FR2  ...        0  NotApplicable   \n",
       "2            Lvl    AllPub    Inside  ...        0  NotApplicable   \n",
       "3            Lvl    AllPub    Corner  ...        0  NotApplicable   \n",
       "4            Lvl    AllPub       FR2  ...        0  NotApplicable   \n",
       "...          ...       ...       ...  ...      ...            ...   \n",
       "1455         Lvl    AllPub    Inside  ...        0  NotApplicable   \n",
       "1456         Lvl    AllPub    Inside  ...        0  NotApplicable   \n",
       "1457         Lvl    AllPub    Inside  ...        0  NotApplicable   \n",
       "1458         Lvl    AllPub    Inside  ...        0  NotApplicable   \n",
       "1459         Lvl    AllPub    Inside  ...        0  NotApplicable   \n",
       "\n",
       "              Fence    MiscFeature MiscVal MoSold  YrSold  SaleType  \\\n",
       "0     NotApplicable  NotApplicable       0      2    2008        WD   \n",
       "1     NotApplicable  NotApplicable       0      5    2007        WD   \n",
       "2     NotApplicable  NotApplicable       0      9    2008        WD   \n",
       "3     NotApplicable  NotApplicable       0      2    2006        WD   \n",
       "4     NotApplicable  NotApplicable       0     12    2008        WD   \n",
       "...             ...            ...     ...    ...     ...       ...   \n",
       "1455  NotApplicable  NotApplicable       0      8    2007        WD   \n",
       "1456          MnPrv  NotApplicable       0      2    2010        WD   \n",
       "1457          GdPrv           Shed    2500      5    2010        WD   \n",
       "1458  NotApplicable  NotApplicable       0      4    2010        WD   \n",
       "1459  NotApplicable  NotApplicable       0      6    2008        WD   \n",
       "\n",
       "      SaleCondition  SalePrice  \n",
       "0            Normal     208500  \n",
       "1            Normal     181500  \n",
       "2            Normal     223500  \n",
       "3           Abnorml     140000  \n",
       "4            Normal     250000  \n",
       "...             ...        ...  \n",
       "1455         Normal     175000  \n",
       "1456         Normal     210000  \n",
       "1457         Normal     266500  \n",
       "1458         Normal     142125  \n",
       "1459         Normal     147500  \n",
       "\n",
       "[1370 rows x 80 columns]>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "df = pd.read_csv(\"houseprices2.csv\")\n",
    "\n",
    "#get all column data types, create dict from colname to dtype\n",
    "datatypes = [x for x in df.dtypes]\n",
    "colnames = df.dtypes.index\n",
    "dict_colname_to_dtype = dict(zip(colnames, datatypes))\n",
    "\n",
    "#get cunts of na values per column\n",
    "na_counts = [x for x in df.isna().sum()]\n",
    "\n",
    "#handle na vals\n",
    "for i in range(len(colnames)):\n",
    "    column_name = colnames[i]\n",
    "    column_type = dict_colname_to_dtype.get(column_name)\n",
    "    column_num_na = na_counts[i]\n",
    "\n",
    "#for categorical columns, create na category\n",
    "    if column_num_na > 10 and column_type == \"object\":\n",
    "        categotical_column = df[column_name]\n",
    "        fixed_column = np.where(categotical_column.isna(), \"NotApplicable\", categotical_column)\n",
    "        df[column_name] = fixed_column\n",
    "\n",
    "#drop any non categorical where more than 10% of data missing\n",
    "    if column_num_na > 150 and column_type != \"object\":\n",
    "        df.drop(column_name, axis = 1, inplace = True)\n",
    "            \n",
    "        \n",
    "print(len(df))\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"houseprices2.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage\n",
      "Alley\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageYrBlt\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PoolQC\n",
      "Fence\n",
      "MiscFeature\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"houseprices2.csv\")\n",
    "columns = list(df.columns)\n",
    "x = df.isna().sum()\n",
    "for i in range(len(x)):\n",
    "    if x[i] > 50:\n",
    "        print(columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix na situation for houseprices 2\n",
    "df = pd.read_csv(\"houseprices2.csv\")\n",
    "\n",
    "pool = df[\"PoolQC\"].tolist()\n",
    "fence = df[\"Fence\"].tolist()\n",
    "misc = df[\"MiscFeature\"].tolist()\n",
    "\n",
    "pool2 = []\n",
    "fence2 = []\n",
    "misc2 = []\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        if np.isnan(pool[i]):\n",
    "            pool2.append(\"NotApplicable\")\n",
    "        else:\n",
    "            pool2.append(pool[i])\n",
    "    except:\n",
    "        pool2.append(pool[i])\n",
    "\n",
    "    try:\n",
    "        if np.isnan(fence[i]):\n",
    "            fence2.append(\"NotApplicable\")\n",
    "        else:\n",
    "            fence2.append(fence[i])\n",
    "    except:\n",
    "        fence2.append(fence[i])\n",
    "\n",
    "    try:\n",
    "        if np.isnan(misc[i]):\n",
    "            misc2.append(\"NotApplicable\")\n",
    "        else:\n",
    "            misc2.append(misc[i])\n",
    "    except:\n",
    "        misc2.append(misc[i])\n",
    "\n",
    "\n",
    "df[\"PoolQC\"] = pool2\n",
    "df[\"Fence\"] = fence2\n",
    "df[\"MiscFeature\"] = misc2\n",
    "\n",
    "print(len(df))\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit and score full baseline model\n",
    "X = df.copy(deep=True)\n",
    "X.drop([\"SalePrice\"], axis=1, inplace=True)\n",
    "y = df[\"SalePrice\"]\n",
    "base_mae = func.trainLinearRegression(X, y)\n",
    "print(base_mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable selection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first new predictor\n",
    "colnames = list(df.columns)\n",
    "colnames.remove(\"SalePrice\")\n",
    "colnames = [[x] for x in colnames]\n",
    "results = Parallel(n_jobs=6)(delayed(func.quickScoreLinearRegression)(i, True) for i in colnames)\n",
    "first_new_colname = colnames[np.argmax(results)]\n",
    "print(f\"Therefore we now add {first_new_colname} as a model feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get second new predictor\n",
    "colnames2 = list(df.columns)\n",
    "colnames2.remove(\"SalePrice\")\n",
    "colnames2.remove(first_new_colname)\n",
    "collnames2 = [[x, first_new_colname] for x in colnames2]\n",
    "results = Parallel(n_jobs=6)(delayed(func.quickScoreLinearRegression)(i, True) for i in colnames2)\n",
    "second_new_colname = colnames2[np.argmax(results)]\n",
    "print(f\"Therefore we now add {second_new_colname} as a model feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get third and final new predictor\n",
    "colnames3 = list(df.columns)\n",
    "colnames3.remove(\"SalePrice\")\n",
    "colnames3.remove(first_new_colname)\n",
    "colnames3.remove(second_new_colname)\n",
    "colnames3 = [[x, first_new_colname, second_new_colname] for x in colnames3]\n",
    "results = Parallel(n_jobs=6)(delayed(func.quickScoreLinearRegression)(i, True) for i in colnames)\n",
    "third_new_colname = colnames3[np.argmax(results)]\n",
    "print(f\"Finally we add {third_new_colname} as a model feature\")\n",
    "print(f\"This gives our model a MAE of {min(results)}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35187.0\n"
     ]
    }
   ],
   "source": [
    "rf_mae = func.quickScoreRandomForest()\n",
    "print(rf_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
